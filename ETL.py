# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qTWeX5jHk9Z3WJkAS1pau82kga0_pnbS
"""

# Instalamos las librerías necesarias
!pip install requests
!pip install pandas

# Importamos  librerías
import requests
import pandas as pd
import json
from datetime import datetime

# Configuración de token y la versión de la API
ACCESS_TOKEN = "IGAATJSKBr5P9BZAE5NblBIMzNqeVJLdXd6c3did3dSYllPa0F3T0p5TlYxWDY0Wk9wbXI4UkRiSzhPOUl2U1VGRzNlZAk44S3pLa2k5UlNLVjhQTU5OVTUxZA2hCUDZAXdTBEeHNodkI2eUVKLXM0LTgwRUdPdnlTZAW9CcC1VWFlmZAwZDZD"
API_VERSION = "v22.0"

# Verificación del token
if not ACCESS_TOKEN or ACCESS_TOKEN == "PASTE_NEW_TOKEN_HERE":
    print("¡Error! Configura un token válido en ACCESS_TOKEN.")
else:
    print("Token configurado:", ACCESS_TOKEN[:10], "... (ocultado por seguridad)")
    print("Versión de la API configurada:", API_VERSION)

# Función para hacer solicitudes a la API: se define una función reusable para enviar solicitudes a la API.
def fetch_instagram_data(endpoint, params, version=API_VERSION):
    url = f"https://graph.instagram.com/{version}/{endpoint}"
    params['access_token'] = ACCESS_TOKEN
    response = requests.get(url, params=params)
    print(f"URL solicitada: {response.url}")  # Para depuración
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Error {response.status_code}: {response.text}")
        return None

print("Función fetch_instagram_data definida")

# Probamos el token con datos básicos del perfil: Se solicita datos básicos del perfil (ID, username, seguidores, número de publicaciones) para verificar que el token funciona.
profile_params = {
    "fields": "id,username,followers_count,media_count"
}
profile_data = fetch_instagram_data("me", profile_params)

if profile_data:
    print("Datos del perfil:")
    print(json.dumps(profile_data, indent=4))
else:
    print("Sin información.")

# Función para manejar la paginación y obtener todas las publicaciones
def fetch_all_instagram_media(params, version=API_VERSION):
    all_media = []
    next_url = f"https://graph.instagram.com/{version}/me/media"

    while next_url:
        response = requests.get(next_url, params=params)
        print(f"URL solicitada: {response.url}")
        if response.status_code != 200:
            print(f"Error {response.status_code}: {response.text}")
            break

        data = response.json()
        if "data" not in data:
            print("Sin información")
            break

        all_media.extend(data["data"])
        # Verifica si hay más páginas
        next_url = data.get("paging", {}).get("next", None)
        params = {}  # Para las siguientes solicitudes, los parámetros están en la URL de paginación

    return all_media

# Configuramos los campos que queremos extraer
media_params = {
    "fields": "id,media_type,media_url,timestamp,like_count,comments_count,children{media_type}",
    "access_token": ACCESS_TOKEN
}

# Extraemos todas las publicaciones
media_data = fetch_all_instagram_media(media_params)

if media_data:
    print("Número total de publicaciones extraídas:", len(media_data))
else:
    print("Sin información")

#Función fetch_all_instagram_media: Maneja la paginación automáticamente. La API devuelve un enlace a la "siguiente página" (paging.next) si hay más publicaciones. La función sigue ese enlace hasta que no haya más datos.

# Convertimos publicaciones a DataFrame y guardamos en CSV
if media_data:
    df_media = pd.DataFrame(media_data)
    df_media["timestamp"] = pd.to_datetime(df_media["timestamp"])
    df_media.to_csv("instagram_media.csv", index=False)
    print("Publicaciones guardadas en 'instagram_media.csv'")
else:
    print("No se guardaron datos.")

#Ajustamos para usar media_data directamente (ya que fetch_all_instagram_media devuelve una lista).
#Guardamos los datos en CSV

if media_data:

# Aseguramos que 'like_count' y 'comments_count' sean numéricos
    df_media['like_count'] = pd.to_numeric(df_media['like_count'], errors='coerce')
    df_media['comments_count'] = pd.to_numeric(df_media['comments_count'], errors='coerce')

# Creamos una columna para interactividad total (likes + comentarios)
    df_media['interactivity'] = df_media['like_count'] + df_media['comments_count']

# Número total de likes y comentarios
    total_likes = df_media['like_count'].sum()
    total_comments = df_media['comments_count'].sum()
    print(f"\nTotal de likes en todas las publicaciones: {total_likes}")
    print(f"Total de comentarios en todas las publicaciones: {total_comments}")

# Promedio de likes y comentarios por publicación
    avg_likes = df_media['like_count'].mean()
    avg_comments = df_media['comments_count'].mean()
    print(f"Promedio de likes por publicación: {avg_likes:.2f}")
    print(f"Promedio de comentarios por publicación: {avg_comments:.2f}")

# Publicación con mayor interactividad
    most_interactive_post = df_media.loc[df_media['interactivity'].idxmax()]
    print("\nPublicación con mayor interactividad:")
    print(f"ID: {most_interactive_post['id']}")
    print(f"Tipo de medio: {most_interactive_post['media_type']}")
    print(f"URL: {most_interactive_post['media_url']}")
    print(f"Fecha: {most_interactive_post['timestamp']}")
    print(f"Likes: {most_interactive_post['like_count']}")
    print(f"Comentarios: {most_interactive_post['comments_count']}")
    print(f"Interactividad total: {most_interactive_post['interactivity']}")

# Publicación con mínima interactividad
    least_interactive_post = df_media.loc[df_media['interactivity'].idxmin()]
    print("\nPublicación con mínima interactividad:")
    print(f"ID: {least_interactive_post['id']}")
    print(f"Tipo de medio: {least_interactive_post['media_type']}")
    print(f"URL: {least_interactive_post['media_url']}")
    print(f"Fecha: {least_interactive_post['timestamp']}")
    print(f"Likes: {least_interactive_post['like_count']}")
    print(f"Comentarios: {least_interactive_post['comments_count']}")
    print(f"Interactividad total: {least_interactive_post['interactivity']}")

# Conteo y análisis por tipo de publicación (videos, imágenes, carruseles)
# Conteo de cada tipo
    media_type_counts = df_media['media_type'].value_counts()
    print("\nConteo de publicaciones por tipo:")
    print(f"Videos: {media_type_counts.get('VIDEO', 0)}")
    print(f"Imágenes: {media_type_counts.get('IMAGE', 0)}")
    print(f"Carruseles: {media_type_counts.get('CAROUSEL_ALBUM', 0)}")

# Análisis por tipo de medio (likes totales, promedio, conteo)
    media_type_analysis = df_media.groupby('media_type').agg({
    'like_count': ['sum', 'mean'],  # Total y promedio de likes
    'comments_count': ['sum', 'mean'],  # Total y promedio de comentarios
    'interactivity': 'mean',  # Promedio de interactividad
    'id': 'count'  # Número de publicaciones

}).reset_index()

# Renombramos las columnas para claridad
media_type_analysis.columns = ['media_type', 'total_likes', 'avg_likes',
                               'total_comments', 'avg_comments', 'avg_interactivity', 'count']

print("\nAnálisis detallado por tipo de publicación:")
print(media_type_analysis)
